{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# 分为三个部分\n",
    "# 1. tokenizer部分\n",
    "# 2. transformer部分\n",
    "# 3. pooling部分\n",
    "\n",
    "\n",
    "# from multiprocessing.pool import Pool\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import psutil\n",
    "from sympy import im\n",
    "from transformers import (AutoConfig, AutoModel, AutoTokenizer)\n",
    "import os\n",
    "import json\n",
    "from sentence_transformers.models import Pooling\n",
    "\n",
    "from sentence_transformers import SentenceTransformer as sbert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################################################\n",
    "# 处理transformer和 tokenizer部分\n",
    "\n",
    "big_model_path = \"../models/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "modules_json_path = os.path.join(big_model_path, 'modules.json')\n",
    "with open(modules_json_path) as fIn:\n",
    "    modules_config = json.load(fIn)\n",
    "\n",
    "tf_from_s_path = os.path.join(big_model_path, modules_config[0].get('path'))\n",
    "\n",
    "\n",
    "# 基本参数\n",
    "\n",
    "max_seq_length = 128\n",
    "doc_stride = 128\n",
    "max_query_length = 64\n",
    "# Enable overwrite to export onnx model and download latest script each time when running this notebook.\n",
    "enable_overwrite = True\n",
    "# Total samples to inference. It shall be large enough to get stable latency measurement.\n",
    "total_samples = 1000\n",
    "\n",
    "\n",
    "# # Load pretrained model and tokenizer\n",
    "# Load pretrained model and tokenizer\n",
    "config_class, model_class, tokenizer_class = (\n",
    "    AutoConfig, AutoModel, AutoTokenizer)\n",
    "\n",
    "cache_dir = os.path.join(\".\", \"cache_models\")\n",
    "config = config_class.from_pretrained(tf_from_s_path, cache_dir=cache_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(\n",
    "    tf_from_s_path, do_lower_case=True, cache_dir=cache_dir)\n",
    "model_transformer = model_class.from_pretrained(\n",
    "    tf_from_s_path, from_tf=False, config=config, cache_dir=cache_dir)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 13:23:41.641149590 [W:onnxruntime:, inference_session.cc:1407 Initialize] Serializing optimized model with Graph Optimization level greater than ORT_ENABLE_EXTENDED and the NchwcTransformer enabled. The generated model may contain hardware specific optimizations, and should only be used in the same environment the model was optimized in.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################################################\n",
    "# 使用onnx 和cuda推理部分\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"onnx_models\")\n",
    "export_model_path = os.path.join(output_dir, 'Multilingual_MiniLM_L12.onnx')\n",
    "\n",
    "device_name = 'gpu'\n",
    "sess_options = onnxruntime.SessionOptions()\n",
    "sess_options.optimized_model_filepath = os.path.join(\n",
    "    output_dir, \"optimized_model_{}.onnx\".format(device_name))\n",
    "# Please change the value according to best setting in Performance Test Tool result.\n",
    "sess_options.intra_op_num_threads = psutil.cpu_count(logical=True)\n",
    "session = onnxruntime.InferenceSession(\n",
    "    export_model_path, sess_options, providers=['CUDAExecutionProvider'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# 处理pooling部分\n",
    "\n",
    "\n",
    "\n",
    "pooling_model_path = os.path.join(big_model_path, modules_config[1].get('path'))\n",
    "\n",
    "pooling_model = Pooling.load(pooling_model_path)\n",
    "# pooling_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "##################################################################################\n",
    "# 生成inputs数据\n",
    "\n",
    "st = ['您好']\n",
    "inputs = tokenizer(\n",
    "    st,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "inputs\n",
    "\n",
    "ort_inputs = {k:v.cpu().numpy() for k, v in inputs.items()}\n",
    "ort_outputs_gpu = session.run(None, ort_inputs)\n",
    "len(ort_outputs_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4, 384), (1, 384)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in ort_outputs_gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.0621e-02,  3.7583e-02,  2.5927e-02,  4.8808e-02,  1.4685e-02,\n",
       "          2.8312e-02, -5.8918e-02,  4.8319e-02,  5.4536e-02,  8.5812e-02,\n",
       "         -7.2008e-02, -6.9941e-02,  1.0563e-02,  1.3090e-02, -5.9875e-02,\n",
       "          6.1503e-02,  1.6375e-02, -8.7087e-02,  2.5770e-02,  6.5209e-02,\n",
       "          8.9911e-02,  2.5373e-02,  5.5006e-02,  6.1519e-03,  1.3298e-03,\n",
       "          2.3704e-03,  6.1129e-02, -1.7243e-02,  2.6797e-02,  7.0297e-02,\n",
       "          1.1463e-02,  1.3976e-02,  3.9850e-02,  1.0488e-02,  1.0850e-02,\n",
       "          1.0893e-02,  3.9947e-02,  2.2994e-02,  8.4140e-03,  5.9997e-02,\n",
       "         -4.8511e-02, -7.4952e-02, -5.5370e-02,  1.4101e-04,  7.7129e-02,\n",
       "         -1.2071e-01,  4.1455e-03, -1.1519e-02,  2.3726e-02, -9.0686e-02,\n",
       "         -1.6727e-02,  7.4755e-02,  7.0669e-02, -7.1630e-03, -9.9254e-02,\n",
       "         -2.9167e-02,  6.5008e-02, -7.0093e-02, -3.6508e-02, -8.5294e-02,\n",
       "         -2.6611e-02, -5.6600e-02, -3.8600e-03,  5.5077e-02,  3.0123e-02,\n",
       "          4.9215e-02,  1.9368e-02, -2.0492e-02,  1.4374e-02,  4.9685e-02,\n",
       "          5.6468e-03,  6.8230e-02, -6.1787e-02, -1.4951e-02,  1.9745e-02,\n",
       "          3.2047e-02,  1.8782e-02,  1.2416e-02,  3.8686e-02, -5.6515e-02,\n",
       "         -6.5258e-02, -5.1521e-02, -1.0040e-02,  1.0227e-01, -6.2697e-02,\n",
       "         -1.1025e-01,  2.6793e-02,  1.5174e-02, -6.9235e-03,  4.8109e-02,\n",
       "         -3.3458e-02, -1.0779e-01,  1.1419e-03, -1.4251e-02, -4.7444e-03,\n",
       "          3.2872e-02, -4.4179e-02, -2.5268e-02,  4.5319e-03,  4.4319e-03,\n",
       "          9.5231e-03,  9.8665e-02,  5.1292e-02, -2.0818e-02, -3.6284e-02,\n",
       "          2.9437e-02,  1.8656e-02,  1.9248e-02, -1.8981e-02, -4.7737e-02,\n",
       "          4.1148e-02,  3.7683e-02,  4.6710e-02, -1.6672e-02,  3.9498e-03,\n",
       "          1.2550e-01,  5.0667e-02, -1.3525e-03,  3.2549e-02,  9.6726e-03,\n",
       "         -5.8216e-02, -9.3676e-02,  8.2888e-02,  2.2938e-02, -9.4618e-03,\n",
       "         -1.1784e-01, -5.9428e-03, -4.8302e-02,  2.6975e-02, -3.1878e-03,\n",
       "          7.3269e-03,  5.0548e-03,  5.2011e-03, -4.0022e-02, -4.7611e-02,\n",
       "         -1.6283e-02, -1.3049e-02,  5.6914e-02, -3.0943e-02, -3.6590e-02,\n",
       "          4.6122e-02,  3.6342e-02,  2.5290e-02, -8.5840e-02, -1.7802e-02,\n",
       "         -7.4507e-02, -2.9004e-02,  3.5383e-02, -5.6978e-03,  2.0760e-02,\n",
       "          1.0054e-02,  4.6702e-02,  4.5702e-02, -3.7285e-02, -2.2796e-02,\n",
       "          7.7588e-02,  3.0423e-02, -2.0918e-02,  1.3799e-02, -1.0799e-01,\n",
       "          5.2015e-03,  4.1641e-02, -2.3365e-02,  6.0428e-02, -2.4036e-03,\n",
       "          4.7127e-02, -1.6207e-02, -2.9299e-02, -7.2130e-05, -1.6172e-02,\n",
       "          2.2670e-02,  1.2056e-02, -5.3208e-02, -6.1044e-02, -4.6998e-02,\n",
       "          7.8005e-02,  6.7002e-02,  3.6592e-02, -7.2732e-02,  1.0782e-02,\n",
       "         -7.8443e-02, -6.7021e-02, -1.1963e-01,  1.1547e-01, -2.5737e-02,\n",
       "          6.2593e-02,  2.1935e-02, -2.6574e-02,  1.7051e-02, -2.4454e-02,\n",
       "         -4.5272e-02, -1.0622e-02,  3.1707e-02,  6.2987e-03,  5.9311e-02,\n",
       "         -1.5906e-02, -6.2322e-02, -3.0650e-02, -7.7925e-02, -2.2322e-02,\n",
       "          7.9976e-02,  9.6784e-02,  2.4539e-02, -6.3780e-02, -1.0782e-03,\n",
       "          3.0894e-03,  4.3153e-03, -5.4323e-02, -4.7410e-02,  3.0520e-02,\n",
       "         -9.0970e-02, -6.8565e-02, -5.7423e-02, -5.8380e-02, -1.6802e-02,\n",
       "         -2.1771e-02,  1.7095e-01,  3.5210e-02, -2.1018e-02, -6.6325e-02,\n",
       "         -3.5125e-02, -4.1628e-02, -9.4643e-04, -3.3140e-02,  2.7940e-02,\n",
       "         -1.6584e-02,  2.2731e-02,  6.9824e-02,  1.7833e-02, -3.5840e-03,\n",
       "          1.0554e-01, -3.5332e-03, -2.1348e-02, -5.6587e-02, -8.3690e-02,\n",
       "         -5.1727e-03,  3.5600e-02, -1.0779e-02, -2.4826e-03,  9.5281e-03,\n",
       "         -4.9314e-02,  1.8523e-02, -2.5880e-03,  7.0712e-02, -6.0117e-02,\n",
       "         -9.0307e-02, -2.2716e-02, -1.1913e-01, -7.6723e-02,  6.5172e-02,\n",
       "         -1.2651e-02,  8.0447e-03, -4.2803e-02,  1.1782e-01, -1.3015e-01,\n",
       "         -1.8687e-02, -7.1296e-02,  8.2676e-02, -6.8440e-02,  2.1916e-02,\n",
       "         -5.2334e-02, -5.2792e-02,  3.9537e-02,  6.3642e-02, -1.1540e-02,\n",
       "          1.8190e-02,  3.5793e-02, -5.9939e-02, -7.7900e-02, -4.3339e-02,\n",
       "         -2.3713e-02, -6.7714e-02, -9.6707e-02, -2.4147e-02,  5.1236e-02,\n",
       "          2.2790e-02,  8.0402e-03, -2.4383e-02,  3.7409e-02,  4.8391e-03,\n",
       "          7.0368e-02, -3.4495e-02, -3.9667e-02,  5.8656e-02,  8.9205e-04,\n",
       "         -5.2431e-02,  2.3343e-02,  1.7418e-02,  7.3477e-03, -2.0096e-02,\n",
       "          1.8379e-02,  1.6592e-02,  1.2032e-02,  3.7124e-02,  1.7855e-01,\n",
       "         -2.4895e-02,  4.1100e-02, -8.6181e-03,  1.8301e-02,  4.3503e-02,\n",
       "         -3.8914e-02,  1.2122e-02,  1.1577e-02, -4.5386e-02, -1.2334e-02,\n",
       "         -6.7824e-03,  1.5666e-02,  5.4268e-03, -1.6022e-03,  5.2996e-02,\n",
       "          4.2203e-02,  6.8222e-02,  8.4950e-02, -9.5773e-02,  6.3752e-02,\n",
       "          9.5438e-02, -7.6180e-02,  8.0920e-02, -2.5799e-02,  2.7407e-02,\n",
       "         -6.5486e-02, -5.5258e-02,  1.5250e-02,  1.8269e-02, -7.2004e-02,\n",
       "          2.8808e-02, -6.1423e-02, -5.8159e-02,  6.9576e-02, -6.3383e-02,\n",
       "          8.3647e-03,  2.3861e-02,  3.4204e-02,  5.8405e-02, -4.3232e-02,\n",
       "         -2.1620e-02,  2.1085e-02, -1.4141e-01,  2.9379e-02, -5.6305e-02,\n",
       "         -3.5024e-02,  4.3235e-02,  3.7951e-03,  1.0809e-02, -5.0352e-02,\n",
       "         -2.8950e-02,  3.3150e-02, -3.6590e-02, -2.5737e-02,  7.4900e-02,\n",
       "          2.4951e-02, -2.4418e-02, -6.6613e-02, -2.6600e-02, -4.5512e-02,\n",
       "         -3.8074e-02,  3.7474e-02, -2.9879e-02, -1.0911e-02,  1.0573e-01,\n",
       "         -5.7630e-02, -1.6653e-02, -1.9409e-02, -1.1758e-02, -2.6021e-02,\n",
       "         -7.0007e-04,  5.0881e-03,  1.0757e-01,  5.8433e-03,  1.1973e-01,\n",
       "          2.5502e-02,  2.1745e-04,  2.7261e-02, -3.0148e-02,  1.9075e-02,\n",
       "         -5.2236e-02, -2.4750e-02,  8.7881e-02,  2.9611e-02,  5.9256e-02,\n",
       "          2.6873e-03,  1.9453e-02, -3.2682e-02, -1.9700e-02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t \n",
    "t.nn.functional.normalize(t.Tensor(ort_outputs_gpu[1]), p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用原生的sentence transformer代码\n",
    "model_sbert_raw = sbert(big_model_path)\n",
    "raw_encode = model_sbert_raw.encode(['您好'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdbb7989f40b9f457e507bcd5a50987663e2e8c6eeb0c3d4331f0628f0ad53bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mynet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
